# deepseek-r1-on-Inter-NPU
deepseek-ai/DeepSeek-R1-Distill-Qwençš„æœ¬åœ°éƒ¨ç½²ï¼ŒNPUç»ˆäºæœ‰ç”¨äº†

## ç¯å¢ƒé…ç½®

```powershell
pip install openvino-genai==2024.6.0
pip install openvino-dev
pip install --upgrade --upgrade-strategy eager optimum[openvino]
ä¸»è¦å°±æ˜¯è¿™å‡ ä¸ªï¼Œå…¶ä»–çš„çœ‹å‡å°‘äº†æ‰‹åŠ¨pipä¸€ä¸‹

# ä¸‹è½½DeepSeek-R1-Distill-Qwen-14Båˆ°æœ¬åœ°å¹¶é‡åŒ–
optimum-cli export openvino --model deepseek-ai/DeepSeek-R1-Distill-Qwen-14B --task text-generation-with-past --weight-format int4 --group-size -1 --ratio 1.0 --sym deepseek-ai\INT4-NPU_compressed_weights 
```

# è¿è¡Œç¤ºä¾‹
```python
import openvino_genai as ov_genai
import re

# å¼ºåŒ–æ¨¡æ¿ç»“æ„ï¼ˆå¢åŠ æ ¼å¼çº¦æŸï¼‰
def deepseek_think_prompt(question):
    return f"""<|im_start|>system
è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
<thinking>
ï¼ˆåœ¨æ­¤è¿›è¡Œå¤šè§’åº¦åˆ†æï¼Œè‡³å°‘åŒ…å«3ä¸ªä¸åŒç§‘å­¦åŸç†ï¼‰
</thinking>
<answer>
ï¼ˆç”¨ä¸¤å¥è¯æ€»ç»“ï¼Œä¸è¶…è¿‡50å­—ï¼‰
</answer>

ç¤ºä¾‹ï¼š
ç”¨æˆ·ï¼šä¸ºä»€ä¹ˆæµ·æ°´æ˜¯å’¸çš„ï¼Ÿ
å›ç­”ï¼š
<thinking>
1. åœ°çƒåŒ–å­¦å¾ªç¯ï¼šé™†åœ°å²©çŸ³ä¸­çš„ç›åˆ†é€šè¿‡æ²³æµå†²åˆ·è¿›å…¥æµ·æ´‹...
2. ç«å±±æ´»åŠ¨ï¼šæµ·åº•ç«å±±é‡Šæ”¾å«çŸ¿ç‰©è´¨çš„çƒ­æ¶²...
3. æ°´åˆ†è’¸å‘ï¼šæµ·æ°´è’¸å‘åªå¸¦èµ°çº¯æ°´ï¼Œç›åˆ†æŒç»­ç§¯ç´¯...</thinking>
<answer>
æµ·æ°´å’¸å‘³æºäºé™†åœ°ç›åˆ†ç»æ²³æµè¾“å…¥å’Œæµ·åº•çŸ¿ç‰©æº¶è§£ï¼Œç»è¿‡æ•°åäº¿å¹´ç§¯ç´¯ï¼Œè’¸å‘ä½œç”¨ä½¿ç›æµ“åº¦ä¿æŒç¨³å®šã€‚</answer><|im_end|>
<|im_start|>user
{question}<|im_end|>
<|im_start|>assistant
"""

# åˆå§‹åŒ–æ¨¡å‹ï¼ˆä¿æŒä½ çš„åŸå§‹è·¯å¾„ï¼‰
pipe = ov_genai.LLMPipeline(r"D:\OpenVINO-model\DeepseekR1-14B\deepseek\INT4-NPU_compressed_weights", device="NPU")

# ä¿®æ­£åçš„ç”Ÿæˆé…ç½®
generation_config = ov_genai.GenerationConfig(
    max_new_tokens=512,    # é€‚å½“ç¼©çŸ­é•¿åº¦
    temperature=0.6,       # å¹³è¡¡æ ¼å¼ç¨³å®šæ€§
    top_p=0.9,
    repetition_penalty=1.1
)

user_question = "ä¸ºä»€ä¹ˆåè£”å°„æ—¥ä¸å°„æ˜ŸæœŸæ—¥"

# ç”Ÿæˆå“åº”
prompt = deepseek_think_prompt(user_question)
output = pipe.generate(prompt, generation_config=generation_config)

# å¼ºåŒ–è§£æé€»è¾‘ï¼ˆå¤„ç†æœªé—­åˆæ ‡ç­¾ï¼‰
def parse_response(text):
    # æ¸…ç†å¯¹è¯æ ‡è®°
    cleaned = re.sub(r"<\|im_.*?\|>", "", text).strip()
    
    # æå–æ€è€ƒéƒ¨åˆ†ï¼ˆå…è®¸ä¸é—­åˆæ ‡ç­¾ï¼‰
    think_match = re.search(r"<thinking>(.*?)(?:</thinking>|$)", cleaned, re.DOTALL|re.IGNORECASE)
    think_content = think_match.group(1).strip() if think_match else ""
    
    # æå–ç­”æ¡ˆéƒ¨åˆ†ï¼ˆæ™ºèƒ½æˆªæ–­ï¼‰
    answer_match = re.search(r"<answer>(.*?)(?:</answer>|$)", cleaned, re.DOTALL|re.IGNORECASE)
    answer_content = answer_match.group(1).strip() if answer_match else ""
    
    # é™çº§å¤„ç†ï¼šå¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æ„åŒ–å†…å®¹
    if not think_content or not answer_content:
        parts = re.split(r"(ç­”æ¡ˆ|ç»“è®º|ç»¼ä¸Š)", cleaned, maxsplit=1, flags=re.I)
        return {
            "thinking": parts[0].strip(),
            "answer": parts[-1].strip("ï¼š: ") if len(parts)>1 else cleaned[-150:]
        }
    
    # æ¸…ç†åµŒå¥—æ ‡ç­¾
    think_content = re.sub(r"</?think.*?>", "", think_content)
    answer_content = re.sub(r"</?answer.*?>", "", answer_content)
    
    return {
        "thinking": "\n".join([line.strip() for line in think_content.split("\n") if line.strip()]),
        "answer": answer_content.split("\n")[0].strip()
    }

# è§£æå¹¶æ‰“å°ç»“æœ
result = parse_response(output)
print("ğŸ”¬ ç§‘å­¦åˆ†æï¼š")
print(result["thinking"])
print("\nğŸ’¡ ç®€æ˜ç»“è®ºï¼š")
print(result["answer"])
```
